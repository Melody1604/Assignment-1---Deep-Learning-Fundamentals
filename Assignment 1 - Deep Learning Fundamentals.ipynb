{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1606c4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in d:\\users\\86186\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\users\\86186\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\users\\86186\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\users\\86186\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\users\\86186\\anaconda3\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "549ea6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   target     768 non-null    int64  \n",
      " 1   feature_0  768 non-null    float64\n",
      " 2   feature_1  768 non-null    float64\n",
      " 3   feature_2  768 non-null    float64\n",
      " 4   feature_3  768 non-null    float64\n",
      " 5   feature_4  768 non-null    float64\n",
      " 6   feature_5  768 non-null    float64\n",
      " 7   feature_6  768 non-null    float64\n",
      " 8   feature_7  768 non-null    float64\n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 54.1 KB\n",
      "None\n",
      "\n",
      "First few rows of the dataset:\n",
      "   target  feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0      -1        6.0      148.0       72.0       35.0        0.0  33.599998   \n",
      "1       1        1.0       85.0       66.0       29.0        0.0  26.600000   \n",
      "2      -1        8.0      183.0       64.0        0.0        0.0  23.299999   \n",
      "3       1        1.0       89.0       66.0       23.0       94.0  28.100000   \n",
      "4      -1        0.0      137.0       40.0       35.0      168.0  43.099998   \n",
      "\n",
      "   feature_6  feature_7  \n",
      "0      0.627       50.0  \n",
      "1      0.351       31.0  \n",
      "2      0.672       32.0  \n",
      "3      0.167       21.0  \n",
      "4      2.288       33.0  \n",
      "\n",
      "Missing values:\n",
      "target       0\n",
      "feature_0    0\n",
      "feature_1    0\n",
      "feature_2    0\n",
      "feature_3    0\n",
      "feature_4    0\n",
      "feature_5    0\n",
      "feature_6    0\n",
      "feature_7    0\n",
      "dtype: int64\n",
      "\n",
      "Basic statistics:\n",
      "           target   feature_0   feature_1   feature_2   feature_3   feature_4  \\\n",
      "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
      "mean     0.302083    3.845052  120.894531   69.105469   20.536458   79.799479   \n",
      "std      0.953903    3.369578   31.972618   19.355807   15.952218  115.244002   \n",
      "min     -1.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%     -1.000000    1.000000   99.000000   62.000000    0.000000    0.000000   \n",
      "50%      1.000000    3.000000  117.000000   72.000000   23.000000   30.500000   \n",
      "75%      1.000000    6.000000  140.250000   80.000000   32.000000  127.250000   \n",
      "max      1.000000   17.000000  199.000000  122.000000   99.000000  846.000000   \n",
      "\n",
      "        feature_5   feature_6   feature_7  \n",
      "count  768.000000  768.000000  768.000000  \n",
      "mean    31.992578    0.471876   33.240885  \n",
      "std      7.884160    0.331329   11.760232  \n",
      "min      0.000000    0.078000   21.000000  \n",
      "25%     27.299999    0.243750   24.000000  \n",
      "50%     32.000000    0.372500   29.000000  \n",
      "75%     36.599998    0.626250   41.000000  \n",
      "max     67.099998    2.420000   81.000000  \n",
      "\n",
      "Processed data saved as 'diabetes.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'diabetes_dataset.txt' \n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "data = []\n",
    "for line in lines:\n",
    "    parts = line.strip().split()\n",
    "    label = int(parts[0])\n",
    "    features = [float(p.split(':')[1]) for p in parts[1:]]\n",
    "    data.append([label] + features)\n",
    "\n",
    "columns = ['target'] + [f'feature_{i}' for i in range(len(data[0])-1)]\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(df.info())\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "df.to_csv('diabetes.csv', index=False)\n",
    "print(\"\\nProcessed data saved as 'diabetes.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16db1f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame:\n",
      "Index(['target', 'feature_0', 'feature_1', 'feature_2', 'feature_3',\n",
      "       'feature_4', 'feature_5', 'feature_6', 'feature_7'],\n",
      "      dtype='object')\n",
      "\n",
      "Training Perceptron with learning rate=0.01, max_iter=1000\n",
      "Validation Accuracy: 69.48%\n",
      "\n",
      "Training Perceptron with learning rate=0.05, max_iter=1000\n",
      "Validation Accuracy: 69.48%\n",
      "\n",
      "Training Perceptron with learning rate=0.1, max_iter=1000\n",
      "Validation Accuracy: 69.48%\n",
      "\n",
      "Best Perceptron Model Parameters: {'learning_rate': 0.01, 'max_iter': 1000}\n",
      "Best Validation Accuracy: 69.48%\n",
      "Perceptron Model Test Accuracy: 65.58%\n",
      "\n",
      "Perceptron Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.51      0.43      0.46        54\n",
      "           1       0.72      0.78      0.75       100\n",
      "\n",
      "    accuracy                           0.66       154\n",
      "   macro avg       0.61      0.60      0.61       154\n",
      "weighted avg       0.64      0.66      0.65       154\n",
      "\n",
      "Confusion Matrix:\n",
      "[[23 31]\n",
      " [22 78]]\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\86186\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.2152 - loss: 0.5841 - val_accuracy: 0.0909 - val_loss: 0.4923\n",
      "Epoch 2/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1571 - loss: 0.4684 - val_accuracy: 0.0909 - val_loss: 0.4029\n",
      "Epoch 3/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1414 - loss: 0.3567 - val_accuracy: 0.0909 - val_loss: 0.3255\n",
      "Epoch 4/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1600 - loss: 0.2974 - val_accuracy: 0.1039 - val_loss: 0.2581\n",
      "Epoch 5/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1544 - loss: 0.0823 - val_accuracy: 0.1299 - val_loss: 0.1852\n",
      "Epoch 6/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2045 - loss: 0.1056 - val_accuracy: 0.1558 - val_loss: 0.1134\n",
      "Epoch 7/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2173 - loss: -0.0959 - val_accuracy: 0.1558 - val_loss: 0.0431\n",
      "Epoch 8/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2230 - loss: -0.1109 - val_accuracy: 0.1688 - val_loss: -0.0225\n",
      "Epoch 9/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2120 - loss: -0.2169 - val_accuracy: 0.1688 - val_loss: -0.1001\n",
      "Epoch 10/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3007 - loss: 0.1520 - val_accuracy: 0.1818 - val_loss: -0.1612\n",
      "Epoch 11/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2929 - loss: -0.4220 - val_accuracy: 0.1753 - val_loss: -0.2515\n",
      "Epoch 12/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2503 - loss: -0.0591 - val_accuracy: 0.1883 - val_loss: -0.3207\n",
      "Epoch 13/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2547 - loss: -0.6545 - val_accuracy: 0.1753 - val_loss: -0.4113\n",
      "Epoch 14/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2656 - loss: -0.1345 - val_accuracy: 0.1883 - val_loss: -0.4849\n",
      "Epoch 15/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2625 - loss: -0.6698 - val_accuracy: 0.1818 - val_loss: -0.5811\n",
      "Epoch 16/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2299 - loss: -0.8858 - val_accuracy: 0.1883 - val_loss: -0.6796\n",
      "Epoch 17/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2937 - loss: -0.8793 - val_accuracy: 0.1883 - val_loss: -0.7801\n",
      "Epoch 18/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2372 - loss: -0.9479 - val_accuracy: 0.1883 - val_loss: -0.8690\n",
      "Epoch 19/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2610 - loss: -1.1933 - val_accuracy: 0.1818 - val_loss: -0.9827\n",
      "Epoch 20/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2593 - loss: -1.1968 - val_accuracy: 0.1883 - val_loss: -1.0932\n",
      "Epoch 21/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2451 - loss: -1.6993 - val_accuracy: 0.1883 - val_loss: -1.2131\n",
      "Epoch 22/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2507 - loss: -1.4046 - val_accuracy: 0.1948 - val_loss: -1.3255\n",
      "Epoch 23/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2470 - loss: -1.6079 - val_accuracy: 0.1948 - val_loss: -1.4541\n",
      "Epoch 24/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2596 - loss: -1.3617 - val_accuracy: 0.2013 - val_loss: -1.5722\n",
      "Epoch 25/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2710 - loss: -1.6623 - val_accuracy: 0.1883 - val_loss: -1.7178\n",
      "Epoch 26/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2406 - loss: -1.8892 - val_accuracy: 0.1948 - val_loss: -1.8470\n",
      "Epoch 27/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2756 - loss: -2.7638 - val_accuracy: 0.1948 - val_loss: -2.0042\n",
      "Epoch 28/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2797 - loss: -2.1541 - val_accuracy: 0.2078 - val_loss: -2.1375\n",
      "Epoch 29/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3086 - loss: -2.2585 - val_accuracy: 0.2078 - val_loss: -2.3029\n",
      "Epoch 30/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2797 - loss: -2.4325 - val_accuracy: 0.2078 - val_loss: -2.4599\n",
      "Epoch 31/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2942 - loss: -1.7665 - val_accuracy: 0.2078 - val_loss: -2.6218\n",
      "Epoch 32/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2501 - loss: -4.2330 - val_accuracy: 0.2013 - val_loss: -2.8132\n",
      "Epoch 33/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2707 - loss: -3.0975 - val_accuracy: 0.2013 - val_loss: -2.9899\n",
      "Epoch 34/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3021 - loss: -3.8639 - val_accuracy: 0.2143 - val_loss: -3.1466\n",
      "Epoch 35/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2500 - loss: -3.2338 - val_accuracy: 0.2078 - val_loss: -3.3455\n",
      "Epoch 36/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2667 - loss: -1.3226 - val_accuracy: 0.2143 - val_loss: -3.5242\n",
      "Epoch 37/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2514 - loss: -3.8377 - val_accuracy: 0.2078 - val_loss: -3.7230\n",
      "Epoch 38/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2618 - loss: -4.4635 - val_accuracy: 0.2078 - val_loss: -3.9287\n",
      "Epoch 39/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2507 - loss: -4.9395 - val_accuracy: 0.2143 - val_loss: -4.1444\n",
      "Epoch 40/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3061 - loss: -2.4818 - val_accuracy: 0.2143 - val_loss: -4.3324\n",
      "Epoch 41/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2760 - loss: -3.6545 - val_accuracy: 0.2143 - val_loss: -4.5639\n",
      "Epoch 42/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3013 - loss: -3.5162 - val_accuracy: 0.2078 - val_loss: -4.7798\n",
      "Epoch 43/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2536 - loss: -3.6579 - val_accuracy: 0.2078 - val_loss: -5.0000\n",
      "Epoch 44/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2283 - loss: -6.2325 - val_accuracy: 0.2078 - val_loss: -5.2568\n",
      "Epoch 45/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2839 - loss: -5.6541 - val_accuracy: 0.2078 - val_loss: -5.5010\n",
      "Epoch 46/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2971 - loss: -5.8279 - val_accuracy: 0.2078 - val_loss: -5.7449\n",
      "Epoch 47/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2767 - loss: -9.1946 - val_accuracy: 0.2078 - val_loss: -6.0026\n",
      "Epoch 48/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2901 - loss: -6.9619 - val_accuracy: 0.2078 - val_loss: -6.2079\n",
      "Epoch 49/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2695 - loss: -7.9144 - val_accuracy: 0.2078 - val_loss: -6.5033\n",
      "Epoch 50/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2703 - loss: -9.0196 - val_accuracy: 0.2078 - val_loss: -6.7483\n",
      "Epoch 51/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2980 - loss: -8.3296 - val_accuracy: 0.2078 - val_loss: -7.0099\n",
      "Epoch 52/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2609 - loss: -5.7685 - val_accuracy: 0.2208 - val_loss: -7.2789\n",
      "Epoch 53/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2665 - loss: -5.7063 - val_accuracy: 0.2078 - val_loss: -7.5564\n",
      "Epoch 54/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2943 - loss: -5.4759 - val_accuracy: 0.2078 - val_loss: -7.8439\n",
      "Epoch 55/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2404 - loss: -6.2380 - val_accuracy: 0.2078 - val_loss: -8.1432\n",
      "Epoch 56/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3011 - loss: -6.1686 - val_accuracy: 0.2078 - val_loss: -8.4337\n",
      "Epoch 57/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2889 - loss: -11.9954 - val_accuracy: 0.2078 - val_loss: -8.7830\n",
      "Epoch 58/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2934 - loss: -8.8960 - val_accuracy: 0.2078 - val_loss: -9.0853\n",
      "Epoch 59/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2459 - loss: -13.2125 - val_accuracy: 0.2078 - val_loss: -9.3957\n",
      "Epoch 60/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2509 - loss: -9.7796 - val_accuracy: 0.2078 - val_loss: -9.6955\n",
      "Epoch 61/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2812 - loss: -15.9129 - val_accuracy: 0.2078 - val_loss: -10.0219\n",
      "Epoch 62/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2665 - loss: -8.7288 - val_accuracy: 0.2143 - val_loss: -10.3266\n",
      "Epoch 63/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2713 - loss: -6.5134 - val_accuracy: 0.2078 - val_loss: -10.6576\n",
      "Epoch 64/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2552 - loss: -12.9326 - val_accuracy: 0.2078 - val_loss: -10.9913\n",
      "Epoch 65/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2738 - loss: -10.7205 - val_accuracy: 0.2078 - val_loss: -11.3490\n",
      "Epoch 66/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2853 - loss: -15.2060 - val_accuracy: 0.2078 - val_loss: -11.7300\n",
      "Epoch 67/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2912 - loss: -14.5593 - val_accuracy: 0.2078 - val_loss: -12.0410\n",
      "Epoch 68/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2884 - loss: -15.4083 - val_accuracy: 0.2078 - val_loss: -12.3704\n",
      "Epoch 69/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2624 - loss: -10.5738 - val_accuracy: 0.2078 - val_loss: -12.7512\n",
      "Epoch 70/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2654 - loss: -9.8980 - val_accuracy: 0.2078 - val_loss: -13.1190\n",
      "Epoch 71/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2546 - loss: -10.5224 - val_accuracy: 0.2078 - val_loss: -13.4554\n",
      "Epoch 72/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2649 - loss: -23.0001 - val_accuracy: 0.2078 - val_loss: -13.8879\n",
      "Epoch 73/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2673 - loss: -15.0002 - val_accuracy: 0.2078 - val_loss: -14.2415\n",
      "Epoch 74/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2415 - loss: -23.7088 - val_accuracy: 0.2078 - val_loss: -14.6591\n",
      "Epoch 75/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2781 - loss: -13.5521 - val_accuracy: 0.2078 - val_loss: -14.9743\n",
      "Epoch 76/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2681 - loss: -18.0655 - val_accuracy: 0.2078 - val_loss: -15.3733\n",
      "Epoch 77/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2554 - loss: -12.2503 - val_accuracy: 0.2078 - val_loss: -15.7211\n",
      "Epoch 78/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2806 - loss: -23.2162 - val_accuracy: 0.2078 - val_loss: -16.1741\n",
      "Epoch 79/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2687 - loss: -19.5967 - val_accuracy: 0.2078 - val_loss: -16.5602\n",
      "Epoch 80/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2619 - loss: -24.1841 - val_accuracy: 0.2078 - val_loss: -16.9720\n",
      "Epoch 81/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2580 - loss: -12.9105 - val_accuracy: 0.2078 - val_loss: -17.3618\n",
      "Epoch 82/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2933 - loss: -18.0865 - val_accuracy: 0.2078 - val_loss: -17.7775\n",
      "Epoch 83/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2754 - loss: -11.4855 - val_accuracy: 0.2078 - val_loss: -18.1893\n",
      "Epoch 84/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2528 - loss: -12.5067 - val_accuracy: 0.2078 - val_loss: -18.6119\n",
      "Epoch 85/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3084 - loss: -21.6274 - val_accuracy: 0.2078 - val_loss: -19.0699\n",
      "Epoch 86/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2914 - loss: -21.5342 - val_accuracy: 0.2078 - val_loss: -19.5192\n",
      "Epoch 87/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2745 - loss: -22.9748 - val_accuracy: 0.2078 - val_loss: -19.9531\n",
      "Epoch 88/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2583 - loss: -31.9427 - val_accuracy: 0.2078 - val_loss: -20.4368\n",
      "Epoch 89/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2690 - loss: -30.4547 - val_accuracy: 0.2078 - val_loss: -20.8506\n",
      "Epoch 90/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2955 - loss: -15.5131 - val_accuracy: 0.2078 - val_loss: -21.2462\n",
      "Epoch 91/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2963 - loss: -17.9814 - val_accuracy: 0.2078 - val_loss: -21.6840\n",
      "Epoch 92/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2869 - loss: -21.0809 - val_accuracy: 0.2078 - val_loss: -22.1648\n",
      "Epoch 93/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2796 - loss: -25.8495 - val_accuracy: 0.2078 - val_loss: -22.6208\n",
      "Epoch 94/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2891 - loss: -20.4312 - val_accuracy: 0.2078 - val_loss: -23.0444\n",
      "Epoch 95/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2911 - loss: -25.5942 - val_accuracy: 0.2078 - val_loss: -23.5726\n",
      "Epoch 96/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2622 - loss: -36.4433 - val_accuracy: 0.2078 - val_loss: -24.0261\n",
      "Epoch 97/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2473 - loss: -34.4734 - val_accuracy: 0.2078 - val_loss: -24.5284\n",
      "Epoch 98/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2876 - loss: -28.2511 - val_accuracy: 0.2078 - val_loss: -24.9277\n",
      "Epoch 99/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2887 - loss: -23.0539 - val_accuracy: 0.2078 - val_loss: -25.4150\n",
      "Epoch 100/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3368 - loss: -27.8784 - val_accuracy: 0.2078 - val_loss: -25.8634\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2806 - loss: -16.4280 \n",
      "\n",
      "CNN Model Test Accuracy: 30.52%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\n",
      "CNN Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        54\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.87      0.47      0.61       100\n",
      "\n",
      "    accuracy                           0.31       154\n",
      "   macro avg       0.29      0.16      0.20       154\n",
      "weighted avg       0.57      0.31      0.40       154\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 47  7]\n",
      " [ 0  0  0]\n",
      " [ 0 53 47]]\n",
      "\n",
      "Perceptron Model Test Accuracy: 65.58%\n",
      "CNN Model Test Accuracy: 30.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\86186\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Users\\86186\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Users\\86186\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Users\\86186\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Users\\86186\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Users\\86186\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Strip whitespace from column names \n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Print columns to verify\n",
    "print(\"Columns in the DataFrame:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Feature Standardization (Z-score normalization)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val)\n",
    "\n",
    "# Implement the Perceptron Model\n",
    "learning_rates = [0.01, 0.05, 0.1]\n",
    "max_iterations = [1000]\n",
    "best_perceptron = None\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for max_iter in max_iterations:\n",
    "        print(f\"\\nTraining Perceptron with learning rate={lr}, max_iter={max_iter}\")\n",
    "        perceptron = Perceptron(\n",
    "            eta0=lr,\n",
    "            max_iter=max_iter,\n",
    "            random_state=42,\n",
    "            early_stopping=True,\n",
    "            validation_fraction=0.1,\n",
    "            n_iter_no_change=10\n",
    "        )\n",
    "        perceptron.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        y_val_pred = perceptron.predict(X_val)\n",
    "        val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "        print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            best_perceptron = perceptron\n",
    "            best_params = {'learning_rate': lr, 'max_iter': max_iter}\n",
    "\n",
    "# Evaluate the Best Perceptron Model on the Test Set\n",
    "print(f\"\\nBest Perceptron Model Parameters: {best_params}\")\n",
    "print(f\"Best Validation Accuracy: {best_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_test_pred_perceptron = best_perceptron.predict(X_test)\n",
    "test_accuracy_perceptron = accuracy_score(y_test, y_test_pred_perceptron)\n",
    "print(f\"Perceptron Model Test Accuracy: {test_accuracy_perceptron * 100:.2f}%\")\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"\\nPerceptron Model Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred_perceptron))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_perceptron))\n",
    "\n",
    "# Implement the CNN Model\n",
    "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_val_cnn = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
    "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Build and Train the CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = cnn_model.fit(\n",
    "    X_train_cnn, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    validation_data=(X_val_cnn, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the CNN Model on the Test Set\n",
    "loss_cnn, accuracy_cnn = cnn_model.evaluate(X_test_cnn, y_test)\n",
    "print(f\"\\nCNN Model Test Accuracy: {accuracy_cnn * 100:.2f}%\")\n",
    "\n",
    "# Predict and generate classification report\n",
    "y_test_pred_cnn = (cnn_model.predict(X_test_cnn) >= 0.5).astype(int).flatten()\n",
    "print(\"\\nCNN Model Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred_cnn))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_cnn))\n",
    "\n",
    "# Compare Model Performance\n",
    "print(f\"\\nPerceptron Model Test Accuracy: {test_accuracy_perceptron * 100:.2f}%\")\n",
    "print(f\"CNN Model Test Accuracy: {accuracy_cnn * 100:.2f}%\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "895b01ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame:\n",
      "Index(['target', 'feature_0', 'feature_1', 'feature_2', 'feature_3',\n",
      "       'feature_4', 'feature_5', 'feature_6', 'feature_7'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Strip whitespace from column names \n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Print columns to verify\n",
    "print(\"Columns in the DataFrame:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Feature Standardization (Z-score normalization)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01df62fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before training, convert labels\n",
    "y_train = np.where(y_train == -1, 0, y_train)\n",
    "y_val = np.where(y_val == -1, 0, y_val)\n",
    "y_test = np.where(y_test == -1, 0, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "068d3b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in y_train: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Confirm labels are 0 and 1\n",
    "print(\"Unique labels in y_train:\", np.unique(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "99ffacff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your labels are originally -1 and 1\n",
    "# Convert labels to 0 and 1\n",
    "y = df['target']\n",
    "y = np.where(y == -1, 0, y)\n",
    "\n",
    "# Update y in train, validation, and test sets after splitting\n",
    "# (Ensure to apply the transformation before splitting to avoid data leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86ef6b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron(early_stopping=True, eta0=0.1, n_iter_no_change=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron(early_stopping=True, eta0=0.1, n_iter_no_change=10, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Perceptron(early_stopping=True, eta0=0.1, n_iter_no_change=10, random_state=42)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels are now 0 and 1\n",
    "# No need to transform labels within the Perceptron class\n",
    "# Proceed to train the Perceptron model as before\n",
    "perceptron.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13015aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Perceptron with learning rate=0.01, max_iter=1000\n",
      "Validation Accuracy: 69.48%\n",
      "\n",
      "Training Perceptron with learning rate=0.05, max_iter=1000\n",
      "Validation Accuracy: 69.48%\n",
      "\n",
      "Training Perceptron with learning rate=0.1, max_iter=1000\n",
      "Validation Accuracy: 69.48%\n",
      "\n",
      "Best Perceptron Model Parameters: {'learning_rate': 0.01, 'max_iter': 1000}\n",
      "Best Validation Accuracy: 69.48%\n",
      "Perceptron Model Test Accuracy: 65.58%\n",
      "\n",
      "Perceptron Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.43      0.46        54\n",
      "           1       0.72      0.78      0.75       100\n",
      "\n",
      "    accuracy                           0.66       154\n",
      "   macro avg       0.61      0.60      0.61       154\n",
      "weighted avg       0.64      0.66      0.65       154\n",
      "\n",
      "Confusion Matrix:\n",
      "[[23 31]\n",
      " [22 78]]\n"
     ]
    }
   ],
   "source": [
    "# Implement the Perceptron Model\n",
    "learning_rates = [0.01, 0.05, 0.1]\n",
    "max_iterations = [1000]\n",
    "best_perceptron = None\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for max_iter in max_iterations:\n",
    "        print(f\"\\nTraining Perceptron with learning rate={lr}, max_iter={max_iter}\")\n",
    "        perceptron = Perceptron(\n",
    "            eta0=lr,\n",
    "            max_iter=max_iter,\n",
    "            random_state=42,\n",
    "            early_stopping=True,\n",
    "            validation_fraction=0.1,\n",
    "            n_iter_no_change=10\n",
    "        )\n",
    "        perceptron.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        y_val_pred = perceptron.predict(X_val)\n",
    "        val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "        print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            best_perceptron = perceptron\n",
    "            best_params = {'learning_rate': lr, 'max_iter': max_iter}\n",
    "\n",
    "# Evaluate the Best Perceptron Model on the Test Set\n",
    "print(f\"\\nBest Perceptron Model Parameters: {best_params}\")\n",
    "print(f\"Best Validation Accuracy: {best_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_test_pred_perceptron = best_perceptron.predict(X_test)\n",
    "test_accuracy_perceptron = accuracy_score(y_test, y_test_pred_perceptron)\n",
    "print(f\"Perceptron Model Test Accuracy: {test_accuracy_perceptron * 100:.2f}%\")\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"\\nPerceptron Model Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred_perceptron))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_perceptron))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c3d82c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\86186\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.4250 - loss: 0.7256 - val_accuracy: 0.6623 - val_loss: 0.6726\n",
      "Epoch 2/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6648 - loss: 0.6487 - val_accuracy: 0.6948 - val_loss: 0.6351\n",
      "Epoch 3/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6945 - loss: 0.6049 - val_accuracy: 0.7078 - val_loss: 0.6086\n",
      "Epoch 4/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7623 - loss: 0.5571 - val_accuracy: 0.7273 - val_loss: 0.5892\n",
      "Epoch 5/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7398 - loss: 0.5523 - val_accuracy: 0.7468 - val_loss: 0.5749\n",
      "Epoch 6/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7758 - loss: 0.5179 - val_accuracy: 0.7468 - val_loss: 0.5635\n",
      "Epoch 7/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8009 - loss: 0.5144 - val_accuracy: 0.7338 - val_loss: 0.5520\n",
      "Epoch 8/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7713 - loss: 0.4899 - val_accuracy: 0.7403 - val_loss: 0.5447\n",
      "Epoch 9/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7368 - loss: 0.5193 - val_accuracy: 0.7273 - val_loss: 0.5367\n",
      "Epoch 10/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7752 - loss: 0.4832 - val_accuracy: 0.7403 - val_loss: 0.5316\n",
      "Epoch 11/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7426 - loss: 0.5026 - val_accuracy: 0.7273 - val_loss: 0.5265\n",
      "Epoch 12/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7901 - loss: 0.4767 - val_accuracy: 0.7338 - val_loss: 0.5222\n",
      "Epoch 13/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7920 - loss: 0.4690 - val_accuracy: 0.7403 - val_loss: 0.5185\n",
      "Epoch 14/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7692 - loss: 0.4867 - val_accuracy: 0.7403 - val_loss: 0.5158\n",
      "Epoch 15/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7992 - loss: 0.4572 - val_accuracy: 0.7532 - val_loss: 0.5130\n",
      "Epoch 16/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7812 - loss: 0.4881 - val_accuracy: 0.7597 - val_loss: 0.5103\n",
      "Epoch 17/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7865 - loss: 0.4651 - val_accuracy: 0.7597 - val_loss: 0.5091\n",
      "Epoch 18/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8040 - loss: 0.4648 - val_accuracy: 0.7597 - val_loss: 0.5076\n",
      "Epoch 19/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7958 - loss: 0.4404 - val_accuracy: 0.7597 - val_loss: 0.5071\n",
      "Epoch 20/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8004 - loss: 0.4702 - val_accuracy: 0.7468 - val_loss: 0.5059\n",
      "Epoch 21/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7722 - loss: 0.4890 - val_accuracy: 0.7597 - val_loss: 0.5039\n",
      "Epoch 22/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8074 - loss: 0.4497 - val_accuracy: 0.7468 - val_loss: 0.5035\n",
      "Epoch 23/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7796 - loss: 0.4658 - val_accuracy: 0.7532 - val_loss: 0.5032\n",
      "Epoch 24/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7764 - loss: 0.4707 - val_accuracy: 0.7597 - val_loss: 0.5022\n",
      "Epoch 25/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7885 - loss: 0.4594 - val_accuracy: 0.7662 - val_loss: 0.5018\n",
      "Epoch 26/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7759 - loss: 0.4803 - val_accuracy: 0.7662 - val_loss: 0.5018\n",
      "Epoch 27/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8057 - loss: 0.4537 - val_accuracy: 0.7727 - val_loss: 0.5017\n",
      "Epoch 28/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7420 - loss: 0.4992 - val_accuracy: 0.7727 - val_loss: 0.5010\n",
      "Epoch 29/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7884 - loss: 0.4691 - val_accuracy: 0.7727 - val_loss: 0.5015\n",
      "Epoch 30/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8228 - loss: 0.4301 - val_accuracy: 0.7727 - val_loss: 0.5011\n",
      "Epoch 31/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8080 - loss: 0.4300 - val_accuracy: 0.7727 - val_loss: 0.5014\n",
      "Epoch 32/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7722 - loss: 0.4761 - val_accuracy: 0.7727 - val_loss: 0.5009\n",
      "Epoch 33/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7734 - loss: 0.4725 - val_accuracy: 0.7727 - val_loss: 0.5014\n",
      "Epoch 34/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7595 - loss: 0.4855 - val_accuracy: 0.7727 - val_loss: 0.5011\n",
      "Epoch 35/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7886 - loss: 0.4944 - val_accuracy: 0.7727 - val_loss: 0.5023\n",
      "Epoch 36/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7992 - loss: 0.4698 - val_accuracy: 0.7727 - val_loss: 0.5018\n",
      "Epoch 37/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7745 - loss: 0.4635 - val_accuracy: 0.7727 - val_loss: 0.5020\n",
      "Epoch 38/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8132 - loss: 0.4601 - val_accuracy: 0.7727 - val_loss: 0.5026\n",
      "Epoch 39/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7868 - loss: 0.4517 - val_accuracy: 0.7727 - val_loss: 0.5020\n",
      "Epoch 40/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8141 - loss: 0.4168 - val_accuracy: 0.7727 - val_loss: 0.5023\n",
      "Epoch 41/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7483 - loss: 0.5217 - val_accuracy: 0.7727 - val_loss: 0.5021\n",
      "Epoch 42/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7879 - loss: 0.4784 - val_accuracy: 0.7792 - val_loss: 0.5026\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7337 - loss: 0.4910 \n",
      "\n",
      "CNN Model Test Accuracy: 74.68%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "CNN Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.54      0.60        54\n",
      "           1       0.77      0.86      0.82       100\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.72      0.70      0.71       154\n",
      "weighted avg       0.74      0.75      0.74       154\n",
      "\n",
      "Confusion Matrix:\n",
      "[[29 25]\n",
      " [14 86]]\n"
     ]
    }
   ],
   "source": [
    "# Implement the CNN Model\n",
    "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_val_cnn = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
    "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Build and Train the CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Labels are 0 and 1\n",
    "# Compile and train the CNN model as before\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = cnn_model.fit(\n",
    "    X_train_cnn, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    validation_data=(X_val_cnn, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the CNN Model on the Test Set\n",
    "loss_cnn, accuracy_cnn = cnn_model.evaluate(X_test_cnn, y_test)\n",
    "print(f\"\\nCNN Model Test Accuracy: {accuracy_cnn * 100:.2f}%\")\n",
    "\n",
    "# Predict and generate classification report\n",
    "y_test_pred_cnn = (cnn_model.predict(X_test_cnn) >= 0.5).astype(int).flatten()\n",
    "print(\"\\nCNN Model Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred_cnn))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cbfee603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.43      0.46        54\n",
      "           1       0.72      0.78      0.75       100\n",
      "\n",
      "    accuracy                           0.66       154\n",
      "   macro avg       0.61      0.60      0.61       154\n",
      "weighted avg       0.64      0.66      0.65       154\n",
      "\n",
      "Confusion Matrix:\n",
      "[[23 31]\n",
      " [22 78]]\n",
      "\n",
      "Perceptron Model Test Accuracy: 65.58%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "CNN Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.54      0.60        54\n",
      "           1       0.77      0.86      0.82       100\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.72      0.70      0.71       154\n",
      "weighted avg       0.74      0.75      0.74       154\n",
      "\n",
      "Confusion Matrix:\n",
      "[[29 25]\n",
      " [14 86]]\n",
      "CNN Model Test Accuracy: 74.68%\n"
     ]
    }
   ],
   "source": [
    "# For both models, predictions will be 0 or 1\n",
    "# Generate classification reports and confusion matrices\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Perceptron Model\n",
    "y_test_pred_perceptron = perceptron.predict(X_test)\n",
    "print(\"Perceptron Model Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred_perceptron))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_perceptron))\n",
    "print(f\"\\nPerceptron Model Test Accuracy: {test_accuracy_perceptron * 100:.2f}%\")\n",
    "\n",
    "# CNN Model\n",
    "y_test_pred_cnn = (cnn_model.predict(X_test_cnn) >= 0.5).astype(int).flatten()\n",
    "print(\"CNN Model Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred_cnn))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_cnn))\n",
    "print(f\"CNN Model Test Accuracy: {accuracy_cnn * 100:.2f}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6fa70b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
